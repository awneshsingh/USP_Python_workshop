{
  "name": "USP python workshop",
  "tagline": "Instructions and material for the University of the South Pacific Python workshop (20-21 Oct. 2016, Suva, Fiji)",
  "body": "# Python for Climate Data Analysis and Visualisation\r\n\r\n[USP](http://www.usp.ac.fj/) / [Pacific Centre for Environment and Sustainable Development (PaCE-SD)](http://pace.usp.ac.fj/) Suva, Fiji, the 20 and 21 October 2016\r\n\r\nContact:\r\n\r\nNicolas Fauchereau\r\n\r\n+ [@gmail](mailto:Nicolas.Fauchereau@gmail.com)\r\n+ [@niwa](mailto:Nicolas.Fauchereau@niwa.co.nz)\r\n\r\n<hr size=5>\r\n\r\n### Table of contents\r\n\r\n- [The Anaconda python distribution](#the-anaconda-python-distribution)\r\n- [Installation of Some additional libraries](#installation-of-additional-libraries)\r\n  - [Basemap](#basemap)\r\n  - [Bokeh](#bokeh)\r\n  - [Seaborn](#seaborn)\r\n  - [mplD3](#mplD3)\r\n  - [bearcart](#bearcart)\r\n  - [folium](#folium)\r\n- [Running the IPython notebooks](#running-the-ipython-notebooks)\r\n- [Troubleshooting](#troubleshooting)\r\n- [Rendered notebooks](#rendered-notebooks)\r\n\r\n<hr size=5>\r\n\r\n## The Anaconda python distribution\r\n\r\nFor this tutorial, I **strongly** recommend installing the **Anaconda Python distribution**. It is a completely free enterprise-ready Python distribution for large-scale data processing, predictive analytics, and scientific computing. It includes the python interpreter itself, the python standard library as well as a set of packages exposing data structures and methods for data manipulation and scientific computing and visualization. In particular it provides [Numpy](http://www.numpy.org/), [Scipy](http://www.scipy.org/), [Pandas](http://pandas.pydata.org/), [Matplotlib](http://matplotlib.org/), [scikit-learn](http://scikit-learn.org/stable/) and [statmodels](http://statsmodels.sourceforge.net/), i.e. all the main packages we will be using during the tutorial. The full list of packages is available at:\r\n\r\n[http://docs.continuum.io/anaconda/pkgs.html](http://docs.continuum.io/anaconda/pkgs.html)\r\n\r\nThe Anaconda python distribution (**NOTE**: select the version shipping with Python 3.5) must be downloaded from:\r\n\r\n[http://continuum.io/downloads](http://continuum.io/downloads)\r\n\r\nFor your platform.\r\n\r\nOnce you have installed Anaconda, you can update to the latest compatible versions of all the pre-installed packages by running:\r\n\r\n```\r\n$ conda update conda\r\n```\r\n\r\nThen\r\n\r\n```\r\n$ conda update anaconda\r\n```\r\n\r\nIn a terminal.\r\n\r\nYou also need to install [pip](https://github.com/pypa/pip) to install packages from the [Python Package Index](http://pypi.python.org/pypi).\r\n\r\n```\r\n$ conda install pip\r\n```\r\n\r\n## Installation of additional libraries\r\n\r\n### netcdf4\r\n\r\n[netcdf4](https://github.com/Unidata/netcdf4-python) allows you to read and write netcdf files (version 3 and 4 supported), install it by:\r\n\r\n```\r\n$ conda install netcdf4\r\n```\r\n\r\n### Basemap\r\n\r\n**Basemap** is a graphic library for plotting (static, publication quality) geographical maps (see [http://matplotlib.org/basemap/](http://matplotlib.org/basemap/)). **Basemap** is available directly in **Anaconda** using the conda package manager, install with:\r\n\r\n```\r\n$ conda install basemap\r\n```\r\n\r\n### Bokeh\r\n\r\n[Bokeh]() is a new interactive plotting library developed by the team behind **anaconda**: it is thus installable with conda (if not already installed):\r\n\r\n```\r\n$ conda install bokeh\r\n```\r\n\r\n### Seaborn\r\n\r\n[seaborn](http://web.stanford.edu/~mwaskom/software/seaborn/) is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics. You should be able to install it with ```conda``` as well:\r\n\r\n```\r\n$ conda install seaborn\r\n```\r\n\r\n### mplD3\r\n\r\n[mplD3](http://mpld3.github.io/) aims at *bringing matplotlib to the browser*. It has been developed by Jake VanDerPlas. It is installable using ```pip```:\r\n\r\n```\r\n$ pip install mpld3\r\n```\r\n\r\n### bearcart\r\n\r\n[bearcart](https://github.com/wrobstory/bearcart) has been developed by [Rob Story](http://wrobstory.github.io/) and provides an interface to the rickshaw JavaScript library. It is also installable via ```pip```:\r\n\r\n```\r\n$ pip install bearcart\r\n```\r\n\r\n### folium\r\n\r\n[folium](https://github.com/wrobstory/folium)  has been also been developed by [Rob Story](http://wrobstory.github.io/) to provide an interface to the [leaflet.js](http://leafletjs.com/) JavaScript mapping library. Install with:\r\n\r\n```\r\n$ pip install folium\r\n```\r\n\r\n<hr size=5>\r\n\r\n### xarray\r\n\r\n[xarray](https://github.com/xarray/xarray) (previously *xray*) is a library aimed at bringing the power of Pandas to multidimensional labelled arrays, such as the ones usually associated with geophysical quantities varying along time and space dimensions (e.g. [time, latitudes, longitudes], [time, level, latitudes, longitudes], etc) and supports reading and writing netcdf files. It can be installed via `conda`:\r\n\r\n```\r\n$ conda install xarray\r\n```\r\n\r\n## Running the Jupyter notebooks\r\n\r\nThe material of the tutorial is in the form of [Jupyter notebooks](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html). In a nutshell a Jupyter notebook is a web-based (i.e. running in the browser) interactive computational environment where you can combine Python code execution, text, mathematics, plots and rich media into a single document, which makes it an ideal medium for teaching and exploring code.\r\n\r\n\r\nAfter uncompressing the archive of the repo (or after cloning it with ```git```), navigate to the corresponding directory (containing the ```*.ipynb``` files, e.g. `session_1/notebooks`) and type:\r\n\r\n```\r\n$ jupyter notebook\r\n```\r\n\r\nThat should bring up the Jupyter notebook dashboard (looking as below), you should be ready to go !\r\n\r\n![](http://nbviewer.ipython.org/github/nicolasfauchereau/Python-for-data-analysis-and-visualisation/blob/master/session_1/notebooks/images/ipython_dashboard.png)\r\n\r\nYou should see in particular a ```test.ipynb``` notebook: please run it to make sure all the necessary libraries have been installed correctly. If you followed the instructions above (install the [anaconda python distribution](http://continuum.io/downloads)) it should be fine, this test notebook is mostly intended for those who have a *custom* python installation.\r\n\r\n## Troubleshooting\r\n\r\nYou might run into some problems installing additional libraries via `conda` or `pip` and / or running the IPython notebooks, especially on Windows machines behind a proxy, here are a few solutions that may work:\r\n\r\n**1. Proxy settings for conda:**\r\n\r\nIf you are behind a proxy, you could encounter some issues. Try first to\r\ncreate a `.condarc` file (the '.' is important) in your HOME directory (on windows it should be `C:\\Users\\YOU`) and add the following lines:\r\n\r\n```\r\nproxy_servers:\r\n    http: http://url:port\r\n    https: http://url:port\r\n```  \r\n\r\n**2. specify proxy when using pip**\r\n\r\nAgain if you are behind a proxy, and if you are running into issues installing libraries via pip, try specifying the proxy to use at the command line, e.g.\r\n\r\n```\r\npip install --proxy=http://url:port bearcart\r\n```\r\n\r\n**3. Set-up system-wide proxy settings**\r\n\r\n+ On Macs: in your `${HOME}/.bash_profile`, insert these lines\r\n\r\n```\r\nexport http_proxy=http://url:port\r\nexport https_proxy=http://url:port\r\n\r\n```\r\n\r\n+ On Linux machines, do the same as above in your `${HOME}/.bashrc`\r\n\r\n+ On Windows machines:\r\n\r\n  + As an administrator go to `Control Panel | System | Advanced Systems Settings | Advanced Tab | Environment Variables | System Variables | New` and set\r\n\r\n  ```\r\n  HTTP_PROXY=http://url:port/\r\n  HTTPS_PROXY=https://url:port/\r\n  ```\r\n\r\n  + You can also do that in a command window by typing (the `$` represents the prompt)\r\n\r\n  ```\r\n  $ SET HTTP_PROXY=http://url:port/\r\n  $ SET HTTPS_PROXY=http://url:port/\r\n  ```\r\n\r\n**4. use Firefox instead of internet explorer to open the notebooks**\r\n\r\n  The Jupyter notebook is an interactive web-based 'notebook', where executable python code can be weaved with rich comments, graphic outputs etc, which make it ideal for presenting interactive tutorials. When (in a command prompt) you navigate to the directory where you have downloaded the notebooks and type (the $ sign represent the prompt):\r\n\r\n  ```\r\n  $ jupyter notebook\r\n  ```\r\n\r\n  a 'dashboard' with the list of notebooks should come up in your browser ... now if you are on windows, chances are that your default browser is Internet Explorer, which is generally bad news. If you encounter problems (blank page, notebooks not loading, kernel interruptions etc), it's probably because of Internet Explorer. What I suggest is that you download [Firefox](https://www.mozilla.org/en-US/firefox/new/) or [Chrome](https://www.google.com/chrome/browser/desktop/) for windows and make it the default browser (your can revert to Internet explorer being the default browser after the workshop if you really want)\r\n\r\n**5. Specify localhost when calling the IPython notebook**\r\n\r\nOn some configurations, you might also need to call:\r\n\r\n```\r\n$ jupyter notebook --ip=127.0.0.1\r\n```\r\n\r\nTo specify that the browser should connect to *localhost*\r\n\r\n**6. Clear the cache**\r\n\r\nIf you are still running into issues (notably dashboard or jupyter notebook not displaying correctly), try *clearing the cache of your browser*\r\n\r\n**7. Use an `incognito` window**\r\n\r\nIf all else fails (!), one thing that has been reported working is:\r\n\r\n+ launch the `jupyter notebook` in no-browser mode:\r\n\r\n```\r\njupyter notebook --no-browser\r\n```\r\n\r\nYou should see an output in the terminal looking like:\r\n\r\n```\r\n...\r\nThe jupyter Notebook is running at: http://localhost:8888/\r\n...\r\n```\r\n\r\nNote that the URL and port could be different in your case.\r\n\r\nOpen an `incognito` window from your browser and copy the URL (`http://localhost:8888/`) in the address bar\r\n\r\n## Rendered notebooks\r\n\r\n**SESSION 1**\r\n\r\n+ [resources and acknowledgments](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/resources.html)\r\n\r\n+ [IPython notebook\r\n  overview](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/IPython_notebook.html)\r\n\r\n+ [Python language basics](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/introduction_python.html)\r\n\r\n+ [Numpy](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/Numpy.html)\r\n\r\n+ [Scipy](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/Scipy.html)\r\n\r\n+ [Matplotlib and Basemap](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/Matplotlib_Basemap.html)\r\n\r\n+ [Pandas](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_1/notebooks/Pandas.html)\r\n\r\n**SESSION 2**\r\n\r\n+ [Interactive plots in the browser](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_2/notebooks/Interactive_plots.html)\r\n\r\n+ [managing your packages and environments with conda](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_2/notebooks/conda.html)\r\n\r\n+ [xray](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_2/notebooks/xray.html)\r\n\r\n+ [brief intro to scikit-learn](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_2/notebooks/sklearn.html)\r\n\r\n+ [EOF decomposition of Pacific SSTs with scikit-learn](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_2/notebooks/sklearn_EOF_decomposition.html)\r\n\r\n+ [k-means clustering of Pacific SSTs with scikit-learn](https://cdn.rawgit.com/nicolasfauchereau/USP_Python_workshop/master/session_2/notebooks/sklearn_kmeans.html)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}